---
layout: page
title: Reporting Delays 
description: Consistency of Reporting Delays
img: assets/img/20260207/market_dynamics_persistence_waterfall_20260207.png
importance: 1
category: work
giscus_comments: false
---

# Empirical Analysis of Reporting Latency and Institutional Tenure


The empirical analysis tracks the longitudinal behavior of approximately 110,000 unique reporting entities over a twenty-two-year study period from 2003 through 2025. By utilizing a high-precision reconciliation pipeline anchored to SEC Accession Numbers, the study isolates the relationship between market experience and regulatory proficiency. The first primary visualization, a cohort-based heatmap titled "Consistency of Reporting Delays Across Years," reveals a striking stability in reporting friction. The asymmetric temporal structure of the map is a logical necessity; the empty upper-right quadrant represents "future" data points where the required tenure exceeds the time remaining in the study window. Most significantly, the heatmap demonstrates cross-cohort uniformity, where "red" and "orange" zones—signifying compliance rates between 50% and 60%—persist vertically across almost all entry years. This proves that the difficulty in meeting the Sarbanes-Oxley 2-day mandate is not merely a "newcomer" issue but a systemic friction affecting the 2003 "vintage" as severely as the 2024 cohort. Furthermore, observing any single calendar year shows that "veteran" insiders with high tenure do not exhibit significantly better profiles than new entrants, indicating a near-zero correlation between market longevity and reporting proficiency.



<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid path=page.img class="img-fluid rounded z-depth-1" %}
    </div>
</div>

## Data Preparation and Engineering

In order to assess the compliance rate over the years, a specialized pipeline was developed to convert unstructured SEC EDGAR filings into a clean, longitudinal dataset. This process involved several critical steps to ensure data integrity over the 22-year study period.

1. Identity Verification via Accession Numbers

The primary challenge in processing legacy filings is "field displacement," where names and ID numbers are often misaligned in the original text. To resolve this, the system used the SEC Accession Number as a "truth anchor". Because the first ten digits of this unique ID are automatically assigned to the filer, the pipeline could verify the identity of the Reporting Owner even when the text within the document was disorganized.

2. Heuristic Extraction and Master Verification

The pipeline scanned the header of each document to identify transaction dates and stock tickers. To prevent the inclusion of "noise" or false data, every extracted Central Index Key (CIK) was cross-checked against the SEC Master Directory. If a number found in the text did not match an official entity in the master list, it was excluded from the study to maintain high precision .

3. Categorization and Storage Efficiency

The software distinguished between individual and institutional entities by searching for corporate markers such as "LLC" or "Corp" in the names. This allowed for a detailed comparison of reporting behavior between different types of market participants. Finally, the data was migrated to a partitioned Parquet format, which reduced the storage size by 70% and enabled efficient computation for the 110,000 entities in the final sample.

Limitations of Human-Driven Compliance

A significant technical hurdle is the persistent "Compliance Ceiling" observed since the introduction of the Sarbanes-Oxley 2-day mandate in 2002 . Because the reconciliation pipeline shows that reporting delays have not improved over two decades, it suggests a structural failure in manual reporting methods.



